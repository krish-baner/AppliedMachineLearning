{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* track the versions of data using dvc\n",
    "* load the raw data into raw_data.csv and save the split data into train.csv/validation.csv/test.csv\n",
    "* update train/validation/test split by choosing different random seed\n",
    "* checkout the first version (before update) using dvc and print the distribution of target variable (number of 0s and number of 1s) in train.csv, validation.csv, and test.csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_PATH = 'sms_spam_collection/SMSSpamCollection'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(FILE_PATH, sep='\\t', names=['label', 'message'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/turing/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /home/turing/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n",
      "[nltk_data] Downloading package stopwords to /home/turing/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
      "[nltk_data] Downloading package wordnet to /home/turing/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [word for word in tokens if word not in stopwords.words('english')]\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['preprocessed_message'] = df['message'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "      <th>preprocessed_message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2869</th>\n",
       "      <td>ham</td>\n",
       "      <td>Aight, tomorrow around  &amp;lt;#&amp;gt;  it is</td>\n",
       "      <td>aight tomorrow around ltgt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2643</th>\n",
       "      <td>ham</td>\n",
       "      <td>They can try! They can get lost, in fact. Tee hee</td>\n",
       "      <td>try get lost fact tee hee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ta-Daaaaa! I am home babe, are you still up ?</td>\n",
       "      <td>tadaaaaa home babe still</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1168</th>\n",
       "      <td>ham</td>\n",
       "      <td>Lol now I'm after that hot air balloon!</td>\n",
       "      <td>lol im hot air balloon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1643</th>\n",
       "      <td>ham</td>\n",
       "      <td>Sleeping nt feeling well</td>\n",
       "      <td>sleeping nt feeling well</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>ham</td>\n",
       "      <td>I accidentally deleted the message. Resend ple...</td>\n",
       "      <td>accidentally deleted message resend please</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1985</th>\n",
       "      <td>spam</td>\n",
       "      <td>Urgent! Please call 09061743810 from landline....</td>\n",
       "      <td>urgent please call landline abta complimentary...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5222</th>\n",
       "      <td>ham</td>\n",
       "      <td>5 nights...We nt staying at port step liao...T...</td>\n",
       "      <td>nightswe nt staying port step liaotoo ex</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3503</th>\n",
       "      <td>ham</td>\n",
       "      <td>I will come to ur home now</td>\n",
       "      <td>come ur home</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2566</th>\n",
       "      <td>ham</td>\n",
       "      <td>I told her I had a Dr appt next week. She thin...</td>\n",
       "      <td>told dr appt next week think im gon na die tol...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     label                                            message  \\\n",
       "2869   ham           Aight, tomorrow around  &lt;#&gt;  it is   \n",
       "2643   ham  They can try! They can get lost, in fact. Tee hee   \n",
       "336    ham      Ta-Daaaaa! I am home babe, are you still up ?   \n",
       "1168   ham            Lol now I'm after that hot air balloon!   \n",
       "1643   ham                           Sleeping nt feeling well   \n",
       "295    ham  I accidentally deleted the message. Resend ple...   \n",
       "1985  spam  Urgent! Please call 09061743810 from landline....   \n",
       "5222   ham  5 nights...We nt staying at port step liao...T...   \n",
       "3503   ham                         I will come to ur home now   \n",
       "2566   ham  I told her I had a Dr appt next week. She thin...   \n",
       "\n",
       "                                   preprocessed_message  \n",
       "2869                         aight tomorrow around ltgt  \n",
       "2643                          try get lost fact tee hee  \n",
       "336                            tadaaaaa home babe still  \n",
       "1168                             lol im hot air balloon  \n",
       "1643                           sleeping nt feeling well  \n",
       "295          accidentally deleted message resend please  \n",
       "1985  urgent please call landline abta complimentary...  \n",
       "5222           nightswe nt staying port step liaotoo ex  \n",
       "3503                                       come ur home  \n",
       "2566  told dr appt next week think im gon na die tol...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label'] = df['label'].map({'ham': 0, 'spam': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized DVC repository.\n",
      "\n",
      "You can now commit the changes to git.\n",
      "\n",
      "\u001b[31m+---------------------------------------------------------------------+\n",
      "\u001b[0m\u001b[31m|\u001b[0m                                                                     \u001b[31m|\u001b[0m\n",
      "\u001b[31m|\u001b[0m        DVC has enabled anonymous aggregate usage analytics.         \u001b[31m|\u001b[0m\n",
      "\u001b[31m|\u001b[0m     Read the analytics documentation (and how to opt-out) here:     \u001b[31m|\u001b[0m\n",
      "\u001b[31m|\u001b[0m             <\u001b[36mhttps://dvc.org/doc/user-guide/analytics\u001b[39m>              \u001b[31m|\u001b[0m\n",
      "\u001b[31m|\u001b[0m                                                                     \u001b[31m|\u001b[0m\n",
      "\u001b[31m+---------------------------------------------------------------------+\n",
      "\u001b[0m\n",
      "\u001b[33mWhat's next?\u001b[39m\n",
      "\u001b[33m------------\u001b[39m\n",
      "- Check out the documentation: <\u001b[36mhttps://dvc.org/doc\u001b[39m>\n",
      "- Get help and share ideas: <\u001b[36mhttps://dvc.org/chat\u001b[39m>\n",
      "- Star us on GitHub: <\u001b[36mhttps://github.com/iterative/dvc\u001b[39m>\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!dvc init --subdir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Version 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into train/validation/test\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "train_df, val_df = train_test_split(train_df, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train :  label\n",
      "0    0.866547\n",
      "1    0.133453\n",
      "Name: count, dtype: float64\n",
      "Validation :  label\n",
      "0    0.863677\n",
      "1    0.136323\n",
      "Name: count, dtype: float64\n",
      "Test :  label\n",
      "0    0.866368\n",
      "1    0.133632\n",
      "Name: count, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# print percentage of each label\n",
    "print(\"Train : \", train_df['label'].value_counts() / len(train_df))\n",
    "print(\"Validation : \", val_df['label'].value_counts() / len(val_df))\n",
    "print(\"Test : \", test_df['label'].value_counts() / len(test_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store the splits at train.csv/validation.csv/test.csv\n",
    "train_df.to_csv('processed_data/train.csv', index=False, sep='\\t')\n",
    "val_df.to_csv('processed_data/validation.csv', index=False, sep='\\t')\n",
    "test_df.to_csv('processed_data/test.csv', index=False, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25l\u001b[32m⠋\u001b[0m Checking graph                                       core\u001b[39m>\n",
      "Adding...                                                                       \n",
      "!\u001b[A\n",
      "Collecting files and computing hashes in processed_data/train.csv |0.00 [00:00, \u001b[A\n",
      "                                                                                \u001b[A\n",
      "!\u001b[A\n",
      "  0% Checking cache in '/mnt/c/Users/saisa/AppliedMachineLearning/assignment_2/.\u001b[A\n",
      "                                                                                \u001b[A\n",
      "!\u001b[A\n",
      "  0%|          |Checking out /mnt/c/Users/saisa/Applie0/1 [00:00<?,    ?files/s]\u001b[A\n",
      "100% Adding...|████████████████████████████████████████|1/1 [00:00,  6.43file/s]\u001b[A\n",
      "\n",
      "To track the changes with git, run:\n",
      "\n",
      "\tgit add processed_data/train.csv.dvc processed_data/.gitignore\n",
      "\n",
      "To enable auto staging, run:\n",
      "\n",
      "\tdvc config core.autostage true\n",
      "\u001b[?25l\u001b[32m⠋\u001b[0m Checking graph                                       core\u001b[39m>\n",
      "Adding...                                                                       \n",
      "!\u001b[A\n",
      "Collecting files and computing hashes in processed_data/validation.csv |0.00 [00\u001b[A\n",
      "                                                                                \u001b[A\n",
      "!\u001b[A\n",
      "  0% Checking cache in '/mnt/c/Users/saisa/AppliedMachineLearning/assignment_2/.\u001b[A\n",
      "                                                                                \u001b[A\n",
      "!\u001b[A\n",
      "  0%|          |Checking out /mnt/c/Users/saisa/Applie0/1 [00:00<?,    ?files/s]\u001b[A\n",
      "100% Adding...|████████████████████████████████████████|1/1 [00:00,  6.81file/s]\u001b[A\n",
      "\n",
      "To track the changes with git, run:\n",
      "\n",
      "\tgit add processed_data/validation.csv.dvc processed_data/.gitignore\n",
      "\n",
      "To enable auto staging, run:\n",
      "\n",
      "\tdvc config core.autostage true\n",
      "\u001b[?25l\u001b[32m⠋\u001b[0m Checking graph                                       core\u001b[39m>\n",
      "Adding...                                                                       \n",
      "!\u001b[A\n",
      "Collecting files and computing hashes in processed_data/test.csv |0.00 [00:00,  \u001b[A\n",
      "                                                                                \u001b[A\n",
      "!\u001b[A\n",
      "  0% Checking cache in '/mnt/c/Users/saisa/AppliedMachineLearning/assignment_2/.\u001b[A\n",
      "                                                                                \u001b[A\n",
      "!\u001b[A\n",
      "  0%|          |Checking out /mnt/c/Users/saisa/Applie0/1 [00:00<?,    ?files/s]\u001b[A\n",
      "100% Adding...|████████████████████████████████████████|1/1 [00:00,  6.18file/s]\u001b[A\n",
      "\n",
      "To track the changes with git, run:\n",
      "\n",
      "\tgit add processed_data/.gitignore processed_data/test.csv.dvc\n",
      "\n",
      "To enable auto staging, run:\n",
      "\n",
      "\tdvc config core.autostage true\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!dvc add processed_data/train.csv\n",
    "!dvc add processed_data/validation.csv\n",
    "!dvc add processed_data/test.csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[detached HEAD 3ffe721] version 1\n",
      " 4 files changed, 21 insertions(+)\n",
      " create mode 100644 assignment_2/processed_data/.gitignore\n",
      " create mode 100644 assignment_2/processed_data/test.csv.dvc\n",
      " create mode 100644 assignment_2/processed_data/train.csv.dvc\n",
      " create mode 100644 assignment_2/processed_data/validation.csv.dvc\n"
     ]
    }
   ],
   "source": [
    "!git add processed_data/train.csv.dvc\n",
    "!git add processed_data/validation.csv.dvc\n",
    "!git add processed_data/test.csv.dvc\n",
    "!git add processed_data/.gitignore\n",
    "!git commit -m \"version 1\"\n",
    "!git tag processed-data-v1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D\tassignment_2/.python-version\n",
      "M\tassignment_2/prepare.ipynb\n",
      "D\tassignment_2/pyproject.toml\n",
      "D\tassignment_2/uv.lock\n",
      "HEAD is now at 3ffe721 version 1\n",
      "Building workspace index                              |8.00 [00:00,  150entry/s]\n",
      "Comparing indexes                                    |9.00 [00:00, 2.96kentry/s]\n",
      "Applying changes                                      |0.00 [00:00,     ?file/s]\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!git checkout processed-data-v1\n",
    "!dvc checkout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train :  label\n",
      "0    0.866547\n",
      "1    0.133453\n",
      "Name: count, dtype: float64\n",
      "Validation :  label\n",
      "0    0.863677\n",
      "1    0.136323\n",
      "Name: count, dtype: float64\n",
      "Test :  label\n",
      "0    0.866368\n",
      "1    0.133632\n",
      "Name: count, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "train_data = pd.read_csv('processed_data/train.csv', sep='\\t')\n",
    "val_data = pd.read_csv('processed_data/validation.csv', sep='\\t')\n",
    "test_data = pd.read_csv('processed_data/test.csv', sep='\\t')\n",
    "\n",
    "print(\"Train : \", train_data['label'].value_counts() / len(train_data))\n",
    "print(\"Validation : \", val_data['label'].value_counts() / len(val_data))\n",
    "print(\"Test : \", test_data['label'].value_counts() / len(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Version 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train :  label\n",
      "0    0.869539\n",
      "1    0.130461\n",
      "Name: count, dtype: float64\n",
      "Validation :  label\n",
      "0    0.867265\n",
      "1    0.132735\n",
      "Name: count, dtype: float64\n",
      "Test :  label\n",
      "0    0.853812\n",
      "1    0.146188\n",
      "Name: count, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=43) # different random seed\n",
    "train_df, val_df = train_test_split(train_df, test_size=0.25, random_state=43) # different random seed\n",
    "\n",
    "print(\"Train : \", train_df['label'].value_counts() / len(train_df))\n",
    "print(\"Validation : \", val_df['label'].value_counts() / len(val_df))\n",
    "print(\"Test : \", test_df['label'].value_counts() / len(test_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv('processed_data/train.csv', index=False, sep='\\t')\n",
    "val_df.to_csv('processed_data/validation.csv', index=False, sep='\\t')\n",
    "test_df.to_csv('processed_data/test.csv', index=False, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25l\u001b[32m⠋\u001b[0m Checking graph                                       core\u001b[39m>\n",
      "Adding...                                                                       \n",
      "!\u001b[A\n",
      "Collecting files and computing hashes in processed_data/train.csv |0.00 [00:00, \u001b[A\n",
      "                                                                                \u001b[A\n",
      "!\u001b[A\n",
      "  0% Checking cache in '/mnt/c/Users/saisa/AppliedMachineLearning/assignment_2/.\u001b[A\n",
      "                                                                                \u001b[A\n",
      "!\u001b[A\n",
      "  0%|          |Adding processed_data/train.csv to cac0/1 [00:00<?,     ?file/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "!\u001b[A\n",
      "  0%|          |Checking out /mnt/c/Users/saisa/Applie0/1 [00:00<?,    ?files/s]\u001b[A\n",
      "100% Adding...|████████████████████████████████████████|1/1 [00:00,  4.55file/s]\u001b[A\n",
      "\n",
      "To track the changes with git, run:\n",
      "\n",
      "\tgit add processed_data/train.csv.dvc\n",
      "\n",
      "To enable auto staging, run:\n",
      "\n",
      "\tdvc config core.autostage true\n",
      "\u001b[?25l                                                                core\u001b[39m>\u001b[32m⠋\u001b[0m Checking graph\n",
      "Adding...                                                                       \n",
      "!\u001b[A\n",
      "Collecting files and computing hashes in processed_data/validation.csv |0.00 [00\u001b[A\n",
      "                                                                                \u001b[A\n",
      "!\u001b[A\n",
      "  0% Checking cache in '/mnt/c/Users/saisa/AppliedMachineLearning/assignment_2/.\u001b[A\n",
      "                                                                                \u001b[A\n",
      "!\u001b[A\n",
      "  0%|          |Adding processed_data/validation.csv t0/1 [00:00<?,     ?file/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "!\u001b[A\n",
      "  0%|          |Checking out /mnt/c/Users/saisa/Applie0/1 [00:00<?,    ?files/s]\u001b[A\n",
      "100% Adding...|████████████████████████████████████████|1/1 [00:00,  4.60file/s]\u001b[A\n",
      "\n",
      "To track the changes with git, run:\n",
      "\n",
      "\tgit add processed_data/validation.csv.dvc\n",
      "\n",
      "To enable auto staging, run:\n",
      "\n",
      "\tdvc config core.autostage true\n",
      "\u001b[?25l\u001b[32m⠋\u001b[0m Checking graph                                       core\u001b[39m>\n",
      "Adding...                                                                       \n",
      "!\u001b[A\n",
      "Collecting files and computing hashes in processed_data/test.csv |0.00 [00:00,  \u001b[A\n",
      "                                                                                \u001b[A\n",
      "!\u001b[A\n",
      "  0% Checking cache in '/mnt/c/Users/saisa/AppliedMachineLearning/assignment_2/.\u001b[A\n",
      "                                                                                \u001b[A\n",
      "!\u001b[A\n",
      "  0%|          |Adding processed_data/test.csv to cach0/1 [00:00<?,     ?file/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "!\u001b[A\n",
      "  0%|          |Checking out /mnt/c/Users/saisa/Applie0/1 [00:00<?,    ?files/s]\u001b[A\n",
      "100% Adding...|████████████████████████████████████████|1/1 [00:00,  4.79file/s]\u001b[A\n",
      "\n",
      "To track the changes with git, run:\n",
      "\n",
      "\tgit add processed_data/test.csv.dvc\n",
      "\n",
      "To enable auto staging, run:\n",
      "\n",
      "\tdvc config core.autostage true\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!dvc add processed_data/train.csv\n",
    "!dvc add processed_data/validation.csv\n",
    "!dvc add processed_data/test.csv\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[detached HEAD 8fea163] version 2\n",
      " 3 files changed, 6 insertions(+), 6 deletions(-)\n"
     ]
    }
   ],
   "source": [
    "!git add processed_data/train.csv.dvc\n",
    "!git add processed_data/validation.csv.dvc\n",
    "!git add processed_data/test.csv.dvc\n",
    "!git add processed_data/.gitignore\n",
    "!git commit -m \"version 2\"\n",
    "!git tag processed-data-v2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D\tassignment_2/.python-version\n",
      "M\tassignment_2/prepare.ipynb\n",
      "D\tassignment_2/pyproject.toml\n",
      "D\tassignment_2/uv.lock\n",
      "HEAD is now at 8fea163 version 2\n",
      "Building workspace index                              |8.00 [00:00,  180entry/s]\n",
      "Comparing indexes                                    |9.00 [00:00, 3.18kentry/s]\n",
      "Applying changes                                      |0.00 [00:00,     ?file/s]\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!git checkout processed-data-v2\n",
    "!dvc checkout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train :  label\n",
      "0    0.869539\n",
      "1    0.130461\n",
      "Name: count, dtype: float64\n",
      "Validation :  label\n",
      "0    0.867265\n",
      "1    0.132735\n",
      "Name: count, dtype: float64\n",
      "Test :  label\n",
      "0    0.853812\n",
      "1    0.146188\n",
      "Name: count, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "train_data = pd.read_csv('processed_data/train.csv', sep='\\t')\n",
    "val_data = pd.read_csv('processed_data/validation.csv', sep='\\t')\n",
    "test_data = pd.read_csv('processed_data/test.csv', sep='\\t')\n",
    "\n",
    "print(\"Train : \", train_data['label'].value_counts() / len(train_data))\n",
    "print(\"Validation : \", val_data['label'].value_counts() / len(val_data))\n",
    "print(\"Test : \", test_data['label'].value_counts() / len(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load versions and check class distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Version 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D\tassignment_2/.python-version\n",
      "M\tassignment_2/prepare.ipynb\n",
      "D\tassignment_2/pyproject.toml\n",
      "D\tassignment_2/uv.lock\n",
      "Previous HEAD position was 8fea163 version 2\n",
      "HEAD is now at 3ffe721 version 1\n",
      "Building workspace index                              |8.00 [00:00, 88.2entry/s]\n",
      "Comparing indexes                                    |9.00 [00:00, 1.62kentry/s]\n",
      "Applying changes                                      |3.00 [00:00,  8.60file/s]\n",
      "\u001b[33mM\u001b[0m       processed_data/validation.csv\n",
      "\u001b[33mM\u001b[0m       processed_data/test.csv\n",
      "\u001b[33mM\u001b[0m       processed_data/train.csv\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!git checkout processed-data-v1\n",
    "!dvc checkout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train :  label\n",
      "0    0.866547\n",
      "1    0.133453\n",
      "Name: count, dtype: float64\n",
      "Validation :  label\n",
      "0    0.863677\n",
      "1    0.136323\n",
      "Name: count, dtype: float64\n",
      "Test :  label\n",
      "0    0.866368\n",
      "1    0.133632\n",
      "Name: count, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "train_data = pd.read_csv('processed_data/train.csv', sep='\\t')\n",
    "val_data = pd.read_csv('processed_data/validation.csv', sep='\\t')\n",
    "test_data = pd.read_csv('processed_data/test.csv', sep='\\t')\n",
    "\n",
    "print(\"Train : \", train_data['label'].value_counts() / len(train_data))\n",
    "print(\"Validation : \", val_data['label'].value_counts() / len(val_data))\n",
    "print(\"Test : \", test_data['label'].value_counts() / len(test_data))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Version 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D\tassignment_2/.python-version\n",
      "M\tassignment_2/prepare.ipynb\n",
      "D\tassignment_2/pyproject.toml\n",
      "D\tassignment_2/uv.lock\n",
      "Previous HEAD position was 3ffe721 version 1\n",
      "HEAD is now at 8fea163 version 2\n",
      "Building workspace index                              |8.00 [00:00, 79.0entry/s]\n",
      "Comparing indexes                                    |9.00 [00:00, 2.00kentry/s]\n",
      "Applying changes                                      |3.00 [00:00,  6.33file/s]\n",
      "\u001b[33mM\u001b[0m       processed_data/train.csv\n",
      "\u001b[33mM\u001b[0m       processed_data/validation.csv\n",
      "\u001b[33mM\u001b[0m       processed_data/test.csv\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!git checkout processed-data-v2\n",
    "!dvc checkout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train :  label\n",
      "0    0.869539\n",
      "1    0.130461\n",
      "Name: count, dtype: float64\n",
      "Validation :  label\n",
      "0    0.867265\n",
      "1    0.132735\n",
      "Name: count, dtype: float64\n",
      "Test :  label\n",
      "0    0.853812\n",
      "1    0.146188\n",
      "Name: count, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "train_data = pd.read_csv('processed_data/train.csv', sep='\\t')\n",
    "val_data = pd.read_csv('processed_data/validation.csv', sep='\\t')\n",
    "test_data = pd.read_csv('processed_data/test.csv', sep='\\t')\n",
    "\n",
    "print(\"Train : \", train_data['label'].value_counts() / len(train_data))\n",
    "print(\"Validation : \", val_data['label'].value_counts() / len(val_data))\n",
    "print(\"Test : \", test_data['label'].value_counts() / len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m8fea163\u001b[m\u001b[33m (\u001b[m\u001b[1;36mHEAD\u001b[m\u001b[33m, \u001b[m\u001b[1;33mtag: processed-data-v2\u001b[m\u001b[33m)\u001b[m version 2\n",
      "\u001b[33m3ffe721\u001b[m\u001b[33m (\u001b[m\u001b[1;33mtag: processed-data-v1\u001b[m\u001b[33m)\u001b[m version 1\n",
      "\u001b[33md2cbeb8\u001b[m\u001b[33m (\u001b[m\u001b[1;33mtag: data-v1\u001b[m\u001b[33m, \u001b[m\u001b[1;32mmain\u001b[m\u001b[33m)\u001b[m version 1\n",
      "\u001b[33m7dc0db7\u001b[m version 1\n",
      "\u001b[33m8819bd3\u001b[m\u001b[33m (\u001b[m\u001b[1;31morigin/main\u001b[m\u001b[33m, \u001b[m\u001b[1;31morigin/HEAD\u001b[m\u001b[33m)\u001b[m initial data\n",
      "\u001b[33m7f0b1ac\u001b[m\u001b[33m (\u001b[m\u001b[1;33mtag: v2\u001b[m\u001b[33m)\u001b[m version 2\n",
      "\u001b[33m8f75402\u001b[m\u001b[33m (\u001b[m\u001b[1;33mtag: v1\u001b[m\u001b[33m)\u001b[m version 1\n",
      "\u001b[33mafb6c85\u001b[m version 2\n",
      "\u001b[33mb70cab0\u001b[m version 1\n",
      "\u001b[33m66394b3\u001b[m version 2\n",
      "\u001b[33m9e0eac3\u001b[m version 1\n",
      "\u001b[33m670633b\u001b[m version 2\n",
      "\u001b[33ma1fc932\u001b[m version 1\n",
      "\u001b[33mf960fd8\u001b[m Add data splits version 1 and 2\n",
      "\u001b[33m580b185\u001b[m train and measure metrics on a bunch of models\n",
      "\u001b[33m2ea28b1\u001b[m load and preprocess data\n",
      "\u001b[33m139493d\u001b[m Initial commit\n"
     ]
    }
   ],
   "source": [
    "!git log --oneline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D\tassignment_2/.python-version\n",
      "M\tassignment_2/prepare.ipynb\n",
      "D\tassignment_2/pyproject.toml\n",
      "D\tassignment_2/uv.lock\n"
     ]
    }
   ],
   "source": [
    "!git checkout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
